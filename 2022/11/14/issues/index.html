<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="HardwareFirmwareSSDSamsung PM1643 or PM1643A drives locked after power cycle Samsung SAS drives PM1643 running EXF7 or EXV7 (high capacity models), or PM1643A running EXA1 or older firmware revisions">
<meta property="og:type" content="article">
<meta property="og:title" content="issues">
<meta property="og:url" content="http://example.com/2022/11/14/issues/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="HardwareFirmwareSSDSamsung PM1643 or PM1643A drives locked after power cycle Samsung SAS drives PM1643 running EXF7 or EXV7 (high capacity models), or PM1643A running EXA1 or older firmware revisions">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-14T07:35:11.000Z">
<meta property="article:modified_time" content="2023-01-16T14:42:58.454Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="trouble">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>issues</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2022/11/14/benchmark/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2022/11/14/mem/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2022/11/14/issues/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2022/11/14/issues/&text=issues"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2022/11/14/issues/&is_video=false&description=issues"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=issues&body=Check out this article: http://example.com/2022/11/14/issues/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2022/11/14/issues/&name=issues&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2022/11/14/issues/&t=issues"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hardware"><span class="toc-number">1.</span> <span class="toc-text">Hardware</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Firmware"><span class="toc-number">1.1.</span> <span class="toc-text">Firmware</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#SSD"><span class="toc-number">1.1.1.</span> <span class="toc-text">SSD</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linux"><span class="toc-number">2.</span> <span class="toc-text">Linux</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#memory"><span class="toc-number">2.1.</span> <span class="toc-text">memory</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#CentOS-default-memory-setting-cause-issue"><span class="toc-number">2.1.1.</span> <span class="toc-text">CentOS default memory setting cause issue</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NIC-page-allocation-failure"><span class="toc-number">3.</span> <span class="toc-text">NIC page allocation failure</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#AMD-PCIE-4-issues"><span class="toc-number">3.1.</span> <span class="toc-text">AMD PCIE 4 issues</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Too-many-futex-overhead"><span class="toc-number">3.2.</span> <span class="toc-text">Too many futex overhead</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CentOS-7-7-sg3-utils-1-37-19-bug"><span class="toc-number">3.3.</span> <span class="toc-text">CentOS 7.7 sg3_utils-1.37-19 bug</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#report-qemu-img-convert-to-LVM-vol-and-show-this-error"><span class="toc-number">3.4.</span> <span class="toc-text">report qemu-img convert to LVM vol and show this error</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kernel-do-IRQ-X-Y-No-irq-handler-for-vector-irq-1"><span class="toc-number">3.5.</span> <span class="toc-text">kernel: do_IRQ: X.Y No irq handler for vector (irq -1)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#multipath-issue"><span class="toc-number">3.6.</span> <span class="toc-text">multipath issue</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PAM-err"><span class="toc-number">3.7.</span> <span class="toc-text">PAM err</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#troubleshooting-1"><span class="toc-number">3.8.</span> <span class="toc-text">troubleshooting-1</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#block-issue"><span class="toc-number">4.</span> <span class="toc-text">block issue</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        issues
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">John Doe</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2022-11-14T07:35:11.000Z" itemprop="datePublished">2022-11-14</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Issues/">Issues</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/trouble/" rel="tag">trouble</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h3 id="Hardware"><a href="#Hardware" class="headerlink" title="Hardware"></a>Hardware</h3><h4 id="Firmware"><a href="#Firmware" class="headerlink" title="Firmware"></a>Firmware</h4><h5 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h5><p><a target="_blank" rel="noopener" href="https://www.dell.com/support/kbdoc/zh-cn/000132949/powerstore-samsung-pm1643-or-pm1643a-drives-locked-after-power-cycle">Samsung PM1643 or PM1643A drives locked after power cycle</a><br> Samsung SAS drives PM1643 running EXF7 or EXV7 (high capacity models), or PM1643A running EXA1 or older firmware revisions may be locked after power cycle.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pre-processing failed device:/dev/sdx exception: Compacket length is zero</span><br><span class="line">processing completed device:/dev/sdx sn:xxxxx success:0</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://www.dell.com/support/kbdoc/en-us/000179687/premature-failures-observed-on-seagate-megalodon-makara-sas-sata-drives-firmware-update-required-to-prevent-premature-failures">seagate firmware update required to prevent premature failures </a></p>
<ul>
<li>The failures have been seen on drives listed below: The root cause has been identified and can be resolved in a firmware updated on the drive. The firmware for each specific drive is listed below.<ul>
<li>It is recommended to upgrade the HDD firmware as soon as possible. After a drive failure, the only option is to replace the drive.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Megalodon	ST2000NM0023	    3.5	6Gbps	SAS	512n	7.2k	2TB	1P7DP	GS14	GS15</span><br><span class="line">Megalodon	ST4000NM0023	   3.5	6Gbps	SAS	512n	7.2k	4TB	529FG	GS14	GS15</span><br><span class="line">Megalodon	ST3000NM0023	   3.5	6Gbps	SAS	512n	7.2k	3TB	55H49	GS14	GS15</span><br><span class="line">Megalodon	ST1000NM0023	   3.5	6Gbps	SAS	512n	7.2k	1TB	FNW88	GS14	GS15</span><br><span class="line">Megalodon	ST4000NM0023	   3.5	6Gbps	SAS	512n	7.2k	4TB	6P85J	GSFA	GSFB</span><br><span class="line">Megalodon	ST500NM0003	   3.5	3Gbps	SATA	512n	7.2k	500GB	2R42K	GA0F	GA10</span><br><span class="line">Megalodon	ST2000NM0033	   3.5	3Gbps	SATA	512n	7.2k	2TB	55FX5	GA0F	GA10</span><br><span class="line">Megalodon	ST1000NM0033	    3.5	3Gbps	SATA	512n	7.2k	1TB	T4XNN	GA0F	GA10</span><br><span class="line">Megalodon	ST3000NM0033	    3.5	3Gbps	SATA	512n	7.2k	3TB	THGNN	GA0F	GA10</span><br><span class="line">Megalodon	ST4000NM0033	    3.5	6Gbps	SATA	512n	7.2k	4TB	9PR63	GA6C	GA6E</span><br><span class="line">Megalodon	ST2000NM0033	    3.5	6Gbps	SATA	512n	7.2k	2TB	PCH77	GA6C	GA6E</span><br><span class="line">Megalodon	ST1000NM0033	    3.5	6Gbps	SATA	512n	7.2k	1TB	W69TH	GA6C	GA6E</span><br><span class="line">Makara	ST2000NM0005	    3.5	12Gbps	SAS	512n	7.2k	2TB	R7FKF	MS05	MS06</span><br><span class="line">Makara	ST6000NM0034	    3.5	6Gbps	SAS	512n	7.2k	6TB	NWCCG	MS2D	MS2E</span><br><span class="line">Makara	ST6000NM0095	    3.5	12Gbps	SAS	512e	7.2k	6TB	MM81X	DE23	DE24</span><br><span class="line">Makara	ST4000NM0005	    3.5	12Gbps	SAS	512n	7.2k	4TB	XWM1W	MS05	MS06</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><h4 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h4><h5 id="CentOS-default-memory-setting-cause-issue"><a href="#CentOS-default-memory-setting-cause-issue" class="headerlink" title="CentOS default memory setting cause issue"></a>CentOS default memory setting cause issue</h5><p><a target="_blank" rel="noopener" href="http://lkml.iu.edu/hypermail/linux/kernel/1904.0/03600.html">nfs hang</a><br>Looks like the min_free_kbytes too low cause ther is no responding in linux kernel and Some reports not in the memory exhaust case.<br>after you setting the mini_free_kbytes, the issue has gone. it ‘s hard to get system log, when you run the dmesg command will hang too.    </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vm.min_free_kbytes=540672</span><br><span class="line">vm.swappiness=5</span><br><span class="line"></span><br><span class="line">min_free_kbytes:</span><br><span class="line">This is used to force the Linux VM to keep a minimum number of kilobytes free.  The VM uses this number to compute a watermark[WMARK_MIN] value <span class="keyword">for</span> each lowmem zone <span class="keyword">in</span> the system. Each lowmem zone gets a number of reserved free pages based proportionally on its size.</span><br><span class="line"></span><br><span class="line">Some minimal amount of memory is needed to satisfy PF_MEMALLOC allocations; <span class="keyword">if</span> you <span class="built_in">set</span> this to lower than 1024KB, your system will become subtly broken, and prone to deadlock under high loads.</span><br><span class="line">Setting this too high will OOM your machine instantly.</span><br></pre></td></tr></table></figure>
<p>(PFMEMALLOC)PF_MEMALLOC means don ‘t care the min watermark &#x3D; ALLOC_NO_WATERMARK      </p>
<h3 id="NIC-page-allocation-failure"><a href="#NIC-page-allocation-failure" class="headerlink" title="NIC page allocation failure"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/641323">NIC page allocation failure</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line">[Mon Jul  2 10:38:25 2018] swapper/16: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Mon Jul  2 10:38:25 2018] CPU: 16 PID: 0 Comm: swapper/16 Tainted: P           OE  ------------   3.10.0-693.5.2.el7_lustre.x86_64 <span class="comment">#1</span></span><br><span class="line">[Mon Jul  2 10:38:25 2018] Hardware name: Dell Inc. PowerEdge R730/072T6D, BIOS 2.4.3 01/17/2017</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  0000000000104020 7e870b98ec876be5 ffff88103e8039d8 ffffffff816a3e2d</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  ffff88103e803a68 ffffffff81188820 0000000000000246 ffff88103e803a28</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  fffffffffffffffc 0010402000000000 ffff88107ffdb018 7e870b98ec876be5</span><br><span class="line">[Mon Jul  2 10:38:25 2018] Call Trace:</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  &lt;IRQ&gt;  [&lt;ffffffff816a3e2d&gt;] dump_stack+0x19/0x1b</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81188820&gt;] warn_alloc_failed+0x110/0x180</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8169fe2a&gt;] __alloc_pages_slowpath+0x6b6/0x724</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8118cdb5&gt;] __alloc_pages_nodemask+0x405/0x420</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff811d1078&gt;] alloc_pages_current+0x98/0x110</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8118761e&gt;] __get_free_pages+0xe/0x40</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff811dca2e&gt;] kmalloc_order_trace+0x2e/0xa0</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffffc031abba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffffc031ba97&gt;] bnx2x_rx_int+0x227/0x17c0 [bnx2x]</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81573004&gt;] ? consume_skb+0x34/0x80</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81585dad&gt;] ? __dev_kfree_skb_any+0x3d/0x50</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffffc031eecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff816b76b6&gt;] do_IRQ+0x56/0xe0</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff816ac2ad&gt;] common_interrupt+0x6d/0x6d</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  &lt;EOI&gt;  [&lt;ffffffff816ab546&gt;] ? native_safe_halt+0x6/0x10</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff816ab3de&gt;] default_idle+0x1e/0xc0</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81035006&gt;] arch_cpu_idle+0x26/0x30</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff810e7bda&gt;] cpu_startup_entry+0x14a/0x1c0</span><br><span class="line">[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81051af6&gt;] start_secondary+0x1b6/0x230</span><br><span class="line"></span><br><span class="line"><span class="comment"># in my case </span></span><br><span class="line">[Thu Jul 12 04:23:16 2018]  00000000ad5e4ed1</span><br><span class="line">[Thu Jul 12 04:23:16 2018] Call Trace:</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  ffff88103e643a20 ffffffff81188820</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  &lt;IRQ&gt;</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  00000000000000c3</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816a3e2d&gt;] dump_stack+0x19/0x1b</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  0000000000000282</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81188820&gt;] warn_alloc_failed+0x110/0x180</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  fffffffffffffffc 0010402000000000</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  ffff8816385ea000 66b8573252d2c8c3</span><br><span class="line">[Thu Jul 12 04:23:16 2018] Call Trace:</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  &lt;IRQ&gt;  [&lt;ffffffff816a3e2d&gt;] dump_stack+0x19/0x1b</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8169fe2a&gt;] __alloc_pages_slowpath+0x6b6/0x724</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81188820&gt;] warn_alloc_failed+0x110/0x180</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811d1078&gt;] alloc_pages_current+0x98/0x110</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f8bba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8169fe2a&gt;] __alloc_pages_slowpath+0x6b6/0x724</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118761e&gt;] __get_free_pages+0xe/0x40</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f9124&gt;] bnx2x_alloc_rx_data.isra.69+0x54/0x1c0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118cdb5&gt;] __alloc_pages_nodemask+0x405/0x420</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811dca2e&gt;] kmalloc_order_trace+0x2e/0xa0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fa0b6&gt;] bnx2x_rx_int+0x846/0x17c0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811d1078&gt;] alloc_pages_current+0x98/0x110</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118761e&gt;] __get_free_pages+0xe/0x40</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f8bba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811dca2e&gt;] kmalloc_order_trace+0x2e/0xa0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f9124&gt;] bnx2x_alloc_rx_data.isra.69+0x54/0x1c0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] ? __kmalloc+0x211/0x230</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f8bba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118cdb5&gt;] __alloc_pages_nodemask+0x405/0x420</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810d1c02&gt;] ? load_balance+0x192/0x9a0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fa0b6&gt;] bnx2x_rx_int+0x846/0x17c0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f9124&gt;] bnx2x_alloc_rx_data.isra.69+0x54/0x1c0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fcecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810d1bd2&gt;] ? load_balance+0x162/0x9a0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fa0b6&gt;] bnx2x_rx_int+0x846/0x17c0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fcecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81573004&gt;] ? consume_skb+0x34/0x80</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81585dad&gt;] ? __dev_kfree_skb_any+0x3d/0x50</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f95c2&gt;] ? bnx2x_free_tx_pkt+0x1f2/0x2d0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f0062&gt;] ? bnx2x_test_link+0x42/0x270 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fcecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811d1078&gt;] alloc_pages_current+0x98/0x110</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118761e&gt;] __get_free_pages+0xe/0x40</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811dca2e&gt;] kmalloc_order_trace+0x2e/0xa0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] ? __kmalloc+0x211/0x230</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b76b6&gt;] do_IRQ+0x56/0xe0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816ac2ad&gt;] common_interrupt+0x6d/0x6d</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  &lt;EOI&gt;</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f8bba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81527d42&gt;] ? cpuidle_enter_state+0x52/0xc0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81527e88&gt;] cpuidle_idle_call+0xd8/0x210</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81034fee&gt;] arch_cpu_idle+0xe/0x30</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810e7bda&gt;] cpu_startup_entry+0x14a/0x1c0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f9124&gt;] bnx2x_alloc_rx_data.isra.69+0x54/0x1c0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fa0b6&gt;] bnx2x_rx_int+0x846/0x17c0 [bnx2x]</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b76b6&gt;] do_IRQ+0x56/0xe0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810d1c02&gt;] ? load_balance+0x192/0x9a0</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816ac2ad&gt;] common_interrupt+0x6d/0x6d</span><br><span class="line">[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110</span><br><span class="line"></span><br><span class="line"><span class="comment"># you can see a lot of processes could not allocation memory</span></span><br><span class="line">[Fri Aug 16 06:08:22 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:08:22 2019] kswapd0: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] kswapd0: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] swapper/10: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 06:43:21 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] kswapd0: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] kswapd0: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] kswapd0: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] systemd-journal: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] swapper/16: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] swapper/16: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] swapper/4: page allocation failure: order:2, mode:0x104020</span><br><span class="line">[Fri Aug 16 09:08:22 2019] swapper/4: page allocation failure: order:2, mode:0x104020</span><br></pre></td></tr></table></figure>
<ul>
<li><p>zone_reclaim_mode</p>
<ul>
<li>sysctl -w vm.zone_reclaim_mode&#x3D;1<ul>
<li>This can be set to 1 to attempt reclamation of memory within a NUMA node before reclaiming from other NUMA nodes. and it’s removed from the latest kernel, only exist in centos7   </li>
<li>Zone_reclaim_mode allows someone to set more or less aggressive approaches to reclaim memory when a zone runs out of memory. If it is set to zero then no zone reclaim occurs. Allocations will be satisfied from other zones &#x2F; nodes in the system.   <ul>
<li>This is value ORed together of  <ul>
<li>1(1)&#x3D; Zone reclaim on    </li>
<li>2(10)&#x3D; Zone reclaim writes dirty pages out   </li>
<li>4(100)&#x3D; Zone reclaim swaps pages   </li>
<li>Only work for the three bit</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><code>min_free_kbytes</code> (it ‘s worked, the page allocation failure was missing)</p>
<ul>
<li>sysctl -w vm.min_free_kbytes &#x3D; 540672<ul>
<li>Increase the virtual memory kernel tunable vm.min_free_kbytes, which instructs the virtual memory subsystem to try keep a certain amount of memory always free for allocation.   </li>
<li>And This parameter modified, the swap usage decrease right now     </li>
<li>The network driver is receiving traffic from the network adapter into kernel memory, however when the driver tried to allocate memory, the allocation failed.    </li>
<li>Kernel memory is required to be a contiguous block of a certain size. The kernel memory may be all consumed or fragmented, hence why a contiguous block could not be allocated.     </li>
<li>Tuning of the system’s use of kernel memory is required to ensure the kernel can always service kernel memory allocations when running in interrupt context.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="AMD-PCIE-4-issues"><a href="#AMD-PCIE-4-issues" class="headerlink" title="AMD PCIE 4 issues"></a>AMD PCIE 4 issues</h4><p><a target="_blank" rel="noopener" href="https://www.dell.com/support/manuals/en-us/red-hat-entps-lx-v7.0/rhel_7_rn_pub/iopagefault-messages-are-displayed-in-dmesg-for-pcie-generation-4-devices?guid=guid-fc7e36fc-34c9-4a82-82c8-a0ad098430a7">IO_PAGE_FAULT messages are displayed in dmesg for PCIe Generation 4 devices</a><br><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/5320571">System logs IO_PAGE_FAULT errors for AMD-Vi</a></p>
<p>Red Hat Enterprise Linux 7.8 and later, centos 8 default parameter: iommu&#x3D;pt (pass-through)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grubby --update-kernel=ALL --args=<span class="string">&#x27;iommu=pt&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="Too-many-futex-overhead"><a href="#Too-many-futex-overhead" class="headerlink" title="Too many futex overhead"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/534663">Too many futex overhead</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ strace -c -f -p <span class="variable">$pid</span></span><br><span class="line">strace: Process 167963 attached with 6 threads</span><br><span class="line">strace: Process 167963 detached</span><br><span class="line">strace: Process 167965 detached</span><br><span class="line">strace: Process 167966 detached</span><br><span class="line">strace: Process 167967 detached</span><br><span class="line">strace: Process 167968 detached</span><br><span class="line">strace: Process 167969 detached</span><br><span class="line">% time     seconds  usecs/call     calls    errors syscall</span><br><span class="line">------ ----------- ----------- --------- --------- ----------------</span><br><span class="line"> 85.85  231.536205          63   3626015    235152 futex</span><br><span class="line">  9.66   26.050936          16   1606480           <span class="built_in">read</span></span><br><span class="line">  4.49   12.108573           7   1606480           lseek</span><br><span class="line">  0.00    0.003128           7       398           brk</span><br><span class="line">  0.00    0.000250          17        14           mmap</span><br><span class="line">  0.00    0.000075          37         2           mremap</span><br><span class="line">------ ----------- ----------- --------- --------- ----------------</span><br><span class="line">100.00  269.699167               6839389    235152 total</span><br></pre></td></tr></table></figure>

<p>Futex calls are used to arbitrate userspace lock contention in applications. If applications are spending a lot of time in futex() system calls then that means there is contention on userspace locks in the application. Is it some massively multi-threaded application?<br>Try reducing the thread count.<br>I think the strace data is sufficient to suggest there is contention in the application and the next step would be to profile the application and how often it acquires whatever synchronisation mechanisms it is using.       </p>
<p>as a workaround turning off ticket spinlocks may help with performance little bit. this can be done by setting ‘spinlock-type&#x3D;unfair’ on grub’s kernel command line   </p>
<p>The futex code uses spinlocks to protect hash bucket queues and spinlocks on RHEL6 are ticketed (ie fair) and performance can really drop off if there is contention from a workload running across numa nodes. The result would be CPUs spending a lot more time busy waiting. We’ll need to know how much of the time spent in futex() is spent sleeping and how much time is spent busy waiting.<br>I ‘m <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html?highlight=kernel%20parameters">not found</a> the parameter “spinlock-type&#x3D;unfair”      </p>
<h4 id="CentOS-7-7-sg3-utils-1-37-19-bug"><a href="#CentOS-7-7-sg3-utils-1-37-19-bug" class="headerlink" title="CentOS 7.7 sg3_utils-1.37-19 bug"></a>CentOS 7.7 sg3_utils-1.37-19 bug</h4><p>The sg3_utils 1.37-19 (centos 7.7 or 7.8) get the wrong JBOD sas slot address from supermicro JBOD, when I upgarde to sg3_utils-1.45, the issue was gone</p>
<h4 id="report-qemu-img-convert-to-LVM-vol-and-show-this-error"><a href="#report-qemu-img-convert-to-LVM-vol-and-show-this-error" class="headerlink" title="report qemu-img convert to LVM vol and show this error"></a><a target="_blank" rel="noopener" href="https://my.oschina.net/LastRitter/blog/1543874">report qemu-img convert to LVM vol and show this error</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel: dm-37: WRITE SAME failed. Manually zeroing.</span><br></pre></td></tr></table></figure>


<h4 id="kernel-do-IRQ-X-Y-No-irq-handler-for-vector-irq-1"><a href="#kernel-do-IRQ-X-Y-No-irq-handler-for-vector-irq-1" class="headerlink" title="kernel: do_IRQ: X.Y No irq handler for vector (irq -1)"></a>kernel: do_IRQ: X.Y No irq handler for vector (irq -1)</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * do_IRQ handles all normal device IRQ&#x27;s (the special</span></span><br><span class="line"><span class="comment"> * SMP cross-CPU interrupts have their own specific</span></span><br><span class="line"><span class="comment"> * handlers).</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">__visible <span class="type">void</span> __irq_entry <span class="title function_">do_IRQ</span><span class="params">(<span class="keyword">struct</span> pt_regs *regs)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">pt_regs</span> *<span class="title">old_regs</span> =</span> set_irq_regs(regs);</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">irq_desc</span> * <span class="title">desc</span>;</span></span><br><span class="line">        <span class="comment">/* high bit used in ret_from_ code  */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="built_in">vector</span> = ~regs-&gt;orig_ax;</span><br><span class="line"></span><br><span class="line">        entering_irq();</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* entering_irq() tells RCU that we&#x27;re not quiescent.  Check it. */</span></span><br><span class="line">        RCU_LOCKDEP_WARN(!rcu_is_watching(), <span class="string">&quot;IRQ failed to wake up RCU&quot;</span>);</span><br><span class="line"></span><br><span class="line">        desc = __this_cpu_read(vector_irq[<span class="built_in">vector</span>]);</span><br><span class="line">        <span class="keyword">if</span> (likely(!IS_ERR_OR_NULL(desc))) &#123;</span><br><span class="line">                <span class="keyword">if</span> (IS_ENABLED(CONFIG_X86_32))</span><br><span class="line">                        handle_irq(desc, regs);</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                        generic_handle_irq_desc(desc);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                ack_APIC_irq();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (desc == VECTOR_UNUSED) &#123;  </span><br><span class="line">                        pr_emerg_ratelimited(<span class="string">&quot;%s: %d.%d No irq handler for vector\n&quot;</span>,</span><br><span class="line">                                             __func__, smp_processor_id(),</span><br><span class="line">                                             <span class="built_in">vector</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        __this_cpu_write(vector_irq[<span class="built_in">vector</span>], VECTOR_UNUSED);</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        exiting_irq();</span><br><span class="line"></span><br><span class="line">        set_irq_regs(old_regs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>system log  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[Tue Apr 28 09:09:19 2020] do_IRQ: 6.95 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 09:23:21 2020] do_IRQ: 2.163 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 09:38:13 2020] do_IRQ: 2.151 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 09:48:55 2020] do_IRQ: 0.155 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 09:49:25 2020] do_IRQ: 2.205 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 09:51:51 2020] do_IRQ: 4.123 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 09:53:05 2020] do_IRQ: 2.208 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 10:29:52 2020] do_IRQ: 6.180 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 10:41:23 2020] do_IRQ: 2.133 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 11:30:06 2020] do_IRQ: 6.191 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 11:39:22 2020] do_IRQ: 4.234 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 11:42:23 2020] do_IRQ: 0.137 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 11:46:53 2020] do_IRQ: 2.38 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 11:57:25 2020] do_IRQ: 6.98 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 12:35:11 2020] do_IRQ: 4.121 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 12:39:12 2020] do_IRQ: 2.163 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 13:05:26 2020] do_IRQ: 0.223 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 14:00:30 2020] do_IRQ: 6.91 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 14:08:06 2020] do_IRQ: 0.159 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line">[Tue Apr 28 14:26:09 2020] do_IRQ: 6.110 No irq handler <span class="keyword">for</span> vector (irq -1)</span><br><span class="line"></span><br><span class="line">$ grep -wEi <span class="string">&#x27;95|98|38|91|121|163&#x27;</span> /proc/interrupts</span><br><span class="line">  38:   98081083          0  142920345          0  123688922          0  172399026          0   PCI-MSI-edge      0000:00:11.4</span><br><span class="line">  91:         34          0         11          0         23          0         18          0   PCI-MSI-edge      em4-fp-7</span><br><span class="line"></span><br><span class="line">00:11.4 SATA controller: Intel Corporation C610/X99 series chipset sSATA Controller [AHCI mode] (rev 05)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Hardware issue # ipmi elist is ok</p>
</li>
<li><p>The hardware driver register num overflow</p>
</li>
<li><p>The hardware driver&#x2F;firmware bug cause responds hobbledown</p>
</li>
<li><p>The bad APIC(programmable interrupt controller) got the wrong IRQ number</p>
<ul>
<li>disable APIC,  noapic pci&#x3D;nomsi,noaer,acpi&#x3D;off</li>
</ul>
</li>
</ul>
<h4 id="multipath-issue"><a href="#multipath-issue" class="headerlink" title="multipath issue"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/2437991">multipath issue</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Jun 14 09:33:38 testhost kernel: blk_cloned_rq_check_limits: over max size <span class="built_in">limit</span>.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: blk_cloned_rq_check_limits: over max size <span class="built_in">limit</span>.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: blk_cloned_rq_check_limits: over max size <span class="built_in">limit</span>.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: blk_cloned_rq_check_limits: over max size <span class="built_in">limit</span>.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: blk_cloned_rq_check_limits: over max size <span class="built_in">limit</span>.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: blk_cloned_rq_check_limits: over max size <span class="built_in">limit</span>.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: blk_cloned_rq_check_limits: over max size <span class="built_in">limit</span>.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: blk_cloned_rq_check_limits: over max size <span class="built_in">limit</span>.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: device-mapper: multipath: Failing path 70:64.</span><br><span class="line">Jun 14 09:33:38 testhost kernel: device-mapper: multipath: Failing path 71:80.</span><br><span class="line">Jun 14 09:33:38 testhost multipathd: 70:64: mark as failed</span><br><span class="line">Jun 14 09:33:38 testhost multipathd: nsd_crs_04: remaining active paths: 1</span><br><span class="line">Jun 14 09:33:38 testhost multipathd: 71:80: mark as failed</span><br><span class="line"></span><br><span class="line"><span class="comment"># show all parameters</span></span><br><span class="line">$ udevadm info --attribute-walk --name=/dev/sdx | grep MG04SCA60EE -i</span><br><span class="line">    ATTRS&#123;model&#125;==<span class="string">&quot;MG04SCA60EE     &quot;</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cat</span> /etc/udev/rules.d/99-custom.rules <span class="comment"># lfs must set to 16383</span></span><br><span class="line">ACTION!=<span class="string">&quot;add|change&quot;</span>, GOTO=<span class="string">&quot;rule_end&quot;</span> ENV&#123;ID_VENDOR&#125;==<span class="string">&quot;NETAPP*&quot;</span>,  RUN+=<span class="string">&quot;/bin/sh -c &#x27;echo 16383 &gt; /sys%p/queue/max_sectors_kb&#x27;&quot;</span> LABEL=<span class="string">&quot;rule_end&quot;</span></span><br><span class="line"></span><br><span class="line">or you could add <span class="string">&quot; max_sectors_kb          16383 &quot;</span> to multipath.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">### add to initramfs</span></span><br><span class="line">$ <span class="built_in">cp</span>  -av  /boot/initramfs-$(<span class="built_in">uname</span> -r).img  /boot/initramfs-$(<span class="built_in">uname</span> -r).img.bak</span><br><span class="line">dracut -f -v -i /etc/udev/rules.d/99-custom.rules /etc/udev/rules.d/99-custom.rules</span><br><span class="line">or</span><br><span class="line">dracut -f -v -i /etc/udev/rules.d/99-custom.rules /etc/multipath.conf</span><br></pre></td></tr></table></figure>

<h4 id="PAM-err"><a href="#PAM-err" class="headerlink" title="PAM err"></a>PAM err</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PAM failed: Authentication service cannot retrieve authentication info</span><br><span class="line"><span class="comment"># in the system log</span></span><br><span class="line"><span class="comment"># the user could not run sudo (have config)</span></span><br><span class="line">resolved: add the userid to the /etc/shadow, it <span class="string">&#x27;s OK</span></span><br></pre></td></tr></table></figure>

<h4 id="troubleshooting-1"><a href="#troubleshooting-1" class="headerlink" title="troubleshooting-1"></a><a target="_blank" rel="noopener" href="https://tanelpoder.com/2013/02/21/peeking-into-linux-kernel-land-using-proc-filesystem-for-quickndirty-troubleshooting/">troubleshooting-1</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br></pre></td><td class="code"><pre><span class="line">[root@oel6 ~]<span class="comment"># ps -ef | grep find</span></span><br><span class="line">root     27288 27245  4 11:57 pts/0    00:00:01 find . -<span class="built_in">type</span> f</span><br><span class="line">root     27334 27315  0 11:57 pts/1    00:00:00 grep find</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># top -cbp 27288</span></span><br><span class="line">top - 11:58:15 up 7 days,  3:38,  2 <span class="built_in">users</span>,  load average: 1.21, 0.65, 0.47</span><br><span class="line">Tasks:   1 total,   0 running,   1 sleeping,   0 stopped,   0 zombie</span><br><span class="line">Cpu(s):  0.1%us,  0.1%sy,  0.0%ni, 99.8%<span class="built_in">id</span>,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st</span><br><span class="line">Mem:   2026460k total,  1935780k used,    90680k free,    64416k buffers</span><br><span class="line">Swap:  4128764k total,   251004k used,  3877760k free,   662280k cached</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND</span><br><span class="line">27288 root      20   0  109m 1160  844 D  0.0  0.1   0:01.11 find . -<span class="built_in">type</span> f</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># strace -cp 27288</span></span><br><span class="line">Process 27288 attached - interrupt to quit</span><br><span class="line"></span><br><span class="line">^C</span><br><span class="line">^Z</span><br><span class="line">[1]+  Stopped                 strace -<span class="built_in">cp</span> 27288</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># kill -9 %%</span></span><br><span class="line">[1]+  Stopped                 strace -<span class="built_in">cp</span> 27288</span><br><span class="line">[root@oel6 ~]<span class="comment">#</span></span><br><span class="line">[1]+  Killed                  strace -<span class="built_in">cp</span> 27288</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># pstack 27288</span></span><br><span class="line"></span><br><span class="line">^C</span><br><span class="line">^Z</span><br><span class="line">[1]+  Stopped                 pstack 27288</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># kill %%</span></span><br><span class="line">[1]+  Stopped                 pstack 27288</span><br><span class="line">[root@oel6 ~]<span class="comment">#</span></span><br><span class="line">[1]+  Terminated              pstack 27288</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># ps -flp 27288</span></span><br><span class="line">F S UID        PID  PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD</span><br><span class="line">0 D root     27288 27245  0  80   0 - 28070 rpc_wa 11:57 pts/0    00:00:01 find . -<span class="built_in">type</span> f</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># cat /proc/27288/wchan</span></span><br><span class="line">rpc_wait_bit_killable</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># cat /proc/27288/status</span></span><br><span class="line">Name:   find</span><br><span class="line">State:  D (disk <span class="built_in">sleep</span>)</span><br><span class="line">Tgid:   27288</span><br><span class="line">Pid:    27288</span><br><span class="line">PPid:   27245</span><br><span class="line">TracerPid:      0</span><br><span class="line">Uid:    0       0       0       0</span><br><span class="line">Gid:    0       0       0       0</span><br><span class="line">FDSize: 256</span><br><span class="line">Groups: 0 1 2 3 4 6 10</span><br><span class="line">VmPeak:   112628 kB</span><br><span class="line">VmSize:   112280 kB</span><br><span class="line">VmLck:         0 kB</span><br><span class="line">VmHWM:      1508 kB</span><br><span class="line">VmRSS:      1160 kB</span><br><span class="line">VmData:      260 kB</span><br><span class="line">VmStk:       136 kB</span><br><span class="line">VmExe:       224 kB</span><br><span class="line">VmLib:      2468 kB</span><br><span class="line">VmPTE:        88 kB</span><br><span class="line">VmSwap:        0 kB</span><br><span class="line">Threads:        1</span><br><span class="line">SigQ:   4/15831</span><br><span class="line">SigPnd: 0000000000040000</span><br><span class="line">ShdPnd: 0000000000000000</span><br><span class="line">SigBlk: 0000000000000000</span><br><span class="line">SigIgn: 0000000000000000</span><br><span class="line">SigCgt: 0000000180000000</span><br><span class="line">CapInh: 0000000000000000</span><br><span class="line">CapPrm: ffffffffffffffff</span><br><span class="line">CapEff: ffffffffffffffff</span><br><span class="line">CapBnd: ffffffffffffffff</span><br><span class="line">Cpus_allowed:   ffffffff,ffffffff</span><br><span class="line">Cpus_allowed_list:      0-63</span><br><span class="line">Mems_allowed:   00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001</span><br><span class="line">Mems_allowed_list:      0</span><br><span class="line">voluntary_ctxt_switches:        9950  &lt;-------------</span><br><span class="line">nonvoluntary_ctxt_switches:     17104 &lt;-------------</span><br><span class="line"></span><br><span class="line">voluntary_ctxt_switches and nonvoluntary_ctxt_switches – this tells you how many <span class="built_in">times</span> the process was taken off CPU (or put back). Then run the same <span class="built_in">command</span> again a few seconds later and see <span class="keyword">if</span> those numbers increase. In my <span class="keyword">case</span> these numbers did not increase, thus I could conclude that the process was completely stuck (well, at least during the few seconds between these commands). So I can be more confident now that this process is completely stuck (and it’s not just flying under the radar by burning 0.04% of CPU all time).</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># cat /proc/27288/sched</span></span><br><span class="line">find (27288, <span class="comment">#threads: 1)</span></span><br><span class="line">---------------------------------------------------------</span><br><span class="line">se.exec_start                      :     617547410.689282</span><br><span class="line">se.vruntime                        :       2471987.542895</span><br><span class="line">se.sum_exec_runtime                :          1119.480311</span><br><span class="line">se.statistics.wait_start           :             0.000000</span><br><span class="line">se.statistics.sleep_start          :             0.000000</span><br><span class="line">se.statistics.block_start          :     617547410.689282</span><br><span class="line">se.statistics.sleep_max            :             0.089192</span><br><span class="line">se.statistics.block_max            :         60082.951331</span><br><span class="line">se.statistics.exec_max             :             1.110465</span><br><span class="line">se.statistics.slice_max            :             0.334211</span><br><span class="line">se.statistics.wait_max             :             0.812834</span><br><span class="line">se.statistics.wait_sum             :           724.745506</span><br><span class="line">se.statistics.wait_count           :                27211</span><br><span class="line">se.statistics.iowait_sum           :             0.000000</span><br><span class="line">se.statistics.iowait_count         :                    0</span><br><span class="line">se.nr_migrations                   :                  312</span><br><span class="line">se.statistics.nr_migrations_cold   :                    0</span><br><span class="line">se.statistics.nr_failed_migrations_affine:                    0</span><br><span class="line">se.statistics.nr_failed_migrations_running:                   96</span><br><span class="line">se.statistics.nr_failed_migrations_hot:                 1794</span><br><span class="line">se.statistics.nr_forced_migrations :                  150</span><br><span class="line">se.statistics.nr_wakeups           :                18507   &lt;-------------</span><br><span class="line">se.statistics.nr_wakeups_sync      :                    1</span><br><span class="line">se.statistics.nr_wakeups_migrate   :                  155</span><br><span class="line">se.statistics.nr_wakeups_local     :                18504</span><br><span class="line">se.statistics.nr_wakeups_remote    :                    3</span><br><span class="line">se.statistics.nr_wakeups_affine    :                  155</span><br><span class="line">se.statistics.nr_wakeups_affine_attempts:                  158</span><br><span class="line">se.statistics.nr_wakeups_passive   :                    0</span><br><span class="line">se.statistics.nr_wakeups_idle      :                    0</span><br><span class="line">avg_atom                           :             0.041379</span><br><span class="line">avg_per_cpu                        :             3.588077</span><br><span class="line">nr_switches                        :                27054  &lt;-------------</span><br><span class="line">nr_voluntary_switches              :                 9950  &lt;-------------</span><br><span class="line">nr_involuntary_switches            :                17104  &lt;-------------</span><br><span class="line">se.load.weight                     :                 1024</span><br><span class="line">policy                             :                    0</span><br><span class="line">prio                               :                  120</span><br><span class="line">clock-delta                        :                   72</span><br><span class="line"></span><br><span class="line">get the context switch counts</span><br><span class="line">nr_switches number (<span class="built_in">which</span> equals nr_voluntary_switches + nr_involuntary_switches)</span><br><span class="line">[root@oel6 ~]<span class="comment"># cat /proc/27288/schedstat</span></span><br><span class="line">1119480311 724745506 27054</span><br><span class="line">                       ^</span><br><span class="line">                       |</span><br><span class="line">                       ------nr_witches</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># cat /proc/27288/syscall</span></span><br><span class="line">262 0xffffffffffffff9c 0x20cf6c8 0x7fff97c52710 0x100 0x100 0x676e776f645f616d 0x7fff97c52658 0x390e2da8ea</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># grep 262 /usr/include/asm/unistd_64.h</span></span><br><span class="line"><span class="comment">#define __NR_newfstatat                         262</span></span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># cat /proc/27288/stack</span></span><br><span class="line">[] rpc_wait_bit_killable+0x24/0x40 [sunrpc]</span><br><span class="line">[] __rpc_execute+0xf5/0x1d0 [sunrpc]</span><br><span class="line">[] rpc_execute+0x43/0x50 [sunrpc]</span><br><span class="line">[] rpc_run_task+0x75/0x90 [sunrpc]</span><br><span class="line">[] rpc_call_sync+0x42/0x70 [sunrpc]</span><br><span class="line">[] nfs3_rpc_wrapper.clone.0+0x35/0x80 [nfs]</span><br><span class="line">[] nfs3_proc_getattr+0x47/0x90 [nfs]</span><br><span class="line">[] __nfs_revalidate_inode+0xcc/0x1f0 [nfs]</span><br><span class="line">[] nfs_revalidate_inode+0x36/0x60 [nfs]</span><br><span class="line">[] nfs_getattr+0x5f/0x110 [nfs]</span><br><span class="line">[] vfs_getattr+0x4e/0x80</span><br><span class="line">[] vfs_fstatat+0x70/0x90</span><br><span class="line">[] sys_newfstatat+0x24/0x50</span><br><span class="line">[] system_call_fastpath+0x16/0x1b</span><br><span class="line">[] 0xffffffffffffffff</span><br><span class="line"></span><br><span class="line">To see whether any of the helper threads are stuck on network-related code, you could sample their kernel stacks too, although the kworkers <span class="keyword">do</span> much more than just NFS RPC communication. During a separate experiment (just copying large files over NFS), I have caught one of the kworkers waiting <span class="keyword">in</span> networking code:</span><br><span class="line"></span><br><span class="line">[root@oel6 proc]<span class="comment"># for i in `pgrep worker` ; do ps -fp $i ; cat /proc/$i/stack ; done</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root        53     2  0 Feb14 ?        00:04:34 [kworker/1:1]</span><br><span class="line">[] __cond_resched+0x2a/0x40</span><br><span class="line">[] lock_sock_nested+0x35/0x70</span><br><span class="line">[] tcp_sendmsg+0x29/0xbe0</span><br><span class="line">[] inet_sendmsg+0x48/0xb0</span><br><span class="line">[] sock_sendmsg+0xef/0x120</span><br><span class="line">[] kernel_sendmsg+0x41/0x60</span><br><span class="line">[] xs_send_kvec+0x8e/0xa0 [sunrpc]</span><br><span class="line">[] xs_sendpages+0x173/0x220 [sunrpc]</span><br><span class="line">[] xs_tcp_send_request+0x5d/0x160 [sunrpc]</span><br><span class="line">[] xprt_transmit+0x83/0x2e0 [sunrpc]</span><br><span class="line">[] call_transmit+0xa8/0x130 [sunrpc]</span><br><span class="line">[] __rpc_execute+0x66/0x1d0 [sunrpc]</span><br><span class="line">[] rpc_async_schedule+0x15/0x20 [sunrpc]</span><br><span class="line">[] process_one_work+0x13e/0x460</span><br><span class="line">[] worker_thread+0x17c/0x3b0</span><br><span class="line">[] kthread+0x96/0xa0</span><br><span class="line">[] kernel_thread_helper+0x4/0x10</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># ps -fp 27288</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root     27288 27245  0 11:57 pts/0    00:00:01 find . -<span class="built_in">type</span> f</span><br><span class="line">[root@oel6 ~]<span class="comment"># kill -9 27288</span></span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># ls -l /proc/27288/stack</span></span><br><span class="line"><span class="built_in">ls</span>: cannot access /proc/27288/stack: No such file or directory</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># ps -fp 27288</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">[root@oel6 ~]<span class="comment">#</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### sort and count syscall</span></span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># export LC_ALL=C ; for i in &#123;1..100&#125; ; do cat /proc/29797/syscall | awk &#x27;&#123; print $1 &#125;&#x27; ; cat /proc/29797/stack | /home/oracle/os_explain -k ; usleep 100000 ; done | sort -r | uniq -c</span></span><br><span class="line">     69 running</span><br><span class="line">      1 ffffff81534c83  &lt;-------------- <span class="built_in">cat</span> /proc/kallsyms | grep -i ffffff81534c83 <span class="comment"># show ffffffff81534c83 t ia32_sysret</span></span><br><span class="line">      2 ffffff81534820</span><br><span class="line">      6 247</span><br><span class="line">     25 180</span><br><span class="line"></span><br><span class="line">    100    0xffffffffffffffff</span><br><span class="line">      1     thread_group_cputime</span><br><span class="line">     27     sysenter_dispatch</span><br><span class="line">      3     ia32_sysret</span><br><span class="line">      1      task_sched_runtime</span><br><span class="line">     27      sys32_pread</span><br><span class="line">      1      compat_sys_io_submit</span><br><span class="line">      2      compat_sys_io_getevents</span><br><span class="line">     27       sys_pread64</span><br><span class="line">      2       sys_io_getevents</span><br><span class="line">      1       do_io_submit</span><br><span class="line">     27        vfs_read</span><br><span class="line">      2        read_events</span><br><span class="line">      1        io_submit_one</span><br><span class="line">     27         do_sync_read</span><br><span class="line">      1         aio_run_iocb</span><br><span class="line">     27          generic_file_aio_read</span><br><span class="line">      1          aio_rw_vect_retry</span><br><span class="line">     27           generic_file_read_iter</span><br><span class="line">      1           generic_file_aio_read</span><br><span class="line">     27            mapping_direct_IO</span><br><span class="line">      1            generic_file_read_iter</span><br><span class="line">     27             blkdev_direct_IO</span><br><span class="line">     27              __blockdev_direct_IO</span><br><span class="line">     27               do_blockdev_direct_IO</span><br><span class="line">     27                dio_post_submission</span><br><span class="line">     27                 dio_await_completion</span><br><span class="line">      6                  blk_flush_plug_list</span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># cat /proc/kallsyms | grep -i ffffff81534820</span></span><br><span class="line">[root@oel6 ~]<span class="comment">#</span></span><br><span class="line"></span><br><span class="line">[root@oel6 ~]<span class="comment"># cat /proc/kallsyms | grep -i ffffff815348</span></span><br><span class="line">ffffffff8153480d t sysenter_do_call</span><br><span class="line">ffffffff81534819 t sysenter_dispatch  &lt;---------------------</span><br><span class="line">ffffffff81534847 t sysexit_from_sys_call</span><br><span class="line">ffffffff8153487a t sysenter_auditsys</span><br><span class="line">ffffffff815348b9 t sysexit_audit</span><br></pre></td></tr></table></figure>

<h3 id="block-issue"><a href="#block-issue" class="headerlink" title="block issue"></a>block issue</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">avg-cpu:  %user   %<span class="built_in">nice</span> %system %iowait  %steal   %idle</span><br><span class="line">           0.00    0.00    6.30    0.03    0.00   93.67</span><br><span class="line"></span><br><span class="line">Device            r/s     w/s     rMB/s     wMB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util</span><br><span class="line">nvme4n1       1969.00    0.00   2523.00      0.00     0.00     0.00   0.00   0.00    0.51    0.00   1.01  1312.11     0.00   0.47  92.40</span><br><span class="line">nvme3n1       1935.00    0.00   2525.00      0.00     0.00     0.00   0.00   0.00    0.51    0.00   1.00  1336.23     0.00   0.47  90.60</span><br><span class="line">nvme1n1       20176.00    1.00   2522.00      0.00     0.00     0.00   0.00   0.00    1.53    0.00  30.92   128.00     4.00   0.05  96.30</span><br><span class="line">nvme2n1       20205.00    0.00   2525.62      0.00     0.00     0.00   0.00   0.00    1.47    0.00  29.71   128.00     0.00   0.05  94.90</span><br><span class="line"></span><br><span class="line">./add_random 0				./add_random 0</span><br><span class="line">./chunk_sectors 0			./chunk_sectors 0</span><br><span class="line">./dax 0					./dax 0</span><br><span class="line">./discard_granularity 512		./discard_granularity 512</span><br><span class="line">./discard_max_bytes 2199023255040	./discard_max_bytes 2199023255040</span><br><span class="line">./discard_max_hw_bytes 2199023255040	./discard_max_hw_bytes 2199023255040</span><br><span class="line">./discard_zeroes_data 0			./discard_zeroes_data 0</span><br><span class="line">./fua 0					./fua 0</span><br><span class="line">./hw_sector_size 512			./hw_sector_size 512</span><br><span class="line">./io_poll 0				./io_poll 0</span><br><span class="line">./io_poll_delay -1			./io_poll_delay -1</span><br><span class="line">./iostats 1				./iostats 1</span><br><span class="line">./io_timeout 30000			./io_timeout 30000</span><br><span class="line">./logical_block_size 512		./logical_block_size 512</span><br><span class="line">./max_discard_segments 256		./max_discard_segments 256</span><br><span class="line">./max_hw_sectors_kb 128			./max_hw_sectors_kb 2048</span><br><span class="line">./max_integrity_segments 0		./max_integrity_segments 0</span><br><span class="line">./max_sectors_kb 128			./max_sectors_kb 2048</span><br><span class="line">./max_segments 33			./max_segments 127</span><br><span class="line">./max_segment_size 65536		./max_segment_size 65536</span><br><span class="line">./minimum_io_size 512			./minimum_io_size 131072</span><br><span class="line">./nomerges 0				./nomerges 0</span><br><span class="line">./nr_requests 1023			./nr_requests 1023</span><br><span class="line">./nr_zones 0				./nr_zones 0</span><br><span class="line">./optimal_io_size 0			./optimal_io_size 131072</span><br><span class="line">./physical_block_size 512		./physical_block_size 4096</span><br><span class="line">./read_ahead_kb 128			./read_ahead_kb 256</span><br><span class="line">./rotational 0				./rotational 0</span><br><span class="line">./rq_affinity 1				./rq_affinity 1</span><br><span class="line">./scheduler [none] mq-deadline kyber bfq	./scheduler [none] mq-deadline kyber bfq</span><br><span class="line">./stable_writes 0			./stable_writes 0</span><br><span class="line">./unpriv_sgio 0				./unpriv_sgio 0</span><br><span class="line">./virt_boundary_mask 4095		./virt_boundary_mask 4095</span><br><span class="line">./wbt_lat_usec 2000			./wbt_lat_usec 2000</span><br><span class="line">./write_cache write through		./write_cache write through</span><br><span class="line">./write_same_max_bytes 0		./write_same_max_bytes 0</span><br><span class="line">./write_zeroes_max_bytes 0		./write_zeroes_max_bytes 2097152</span><br><span class="line">./zone_append_max_bytes 0		./zone_append_max_bytes 0</span><br><span class="line">./zoned none				./zoned none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># dell me5 SAN SAS SSD</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(<span class="built_in">ls</span> /sys/block/sdu/queue/); <span class="keyword">do</span> <span class="built_in">echo</span> -n <span class="variable">$i</span><span class="string">&quot; &quot;</span>$(<span class="built_in">cat</span> /sys/block/sdu/queue/<span class="variable">$i</span>); <span class="built_in">echo</span>; <span class="keyword">done</span> </span><br><span class="line">add_random 1</span><br><span class="line">chunk_sectors 0</span><br><span class="line">dax 0</span><br><span class="line">discard_granularity 0</span><br><span class="line">discard_max_bytes 0</span><br><span class="line">discard_max_hw_bytes 0</span><br><span class="line">discard_zeroes_data 0</span><br><span class="line">fua 0</span><br><span class="line">hw_sector_size 512</span><br><span class="line">io_poll 0</span><br><span class="line">io_poll_delay -1</span><br><span class="line"><span class="built_in">cat</span>: /sys/block/sdu/queue/iosched: Is a directory</span><br><span class="line">iosched </span><br><span class="line">iostats 1</span><br><span class="line">io_timeout 30000</span><br><span class="line">logical_block_size 512</span><br><span class="line">max_discard_segments 1</span><br><span class="line">max_hw_sectors_kb 16383</span><br><span class="line">max_integrity_segments 0</span><br><span class="line">max_sectors_kb 1024</span><br><span class="line">max_segments 128</span><br><span class="line">max_segment_size 65536</span><br><span class="line">minimum_io_size 4096</span><br><span class="line">nomerges 0</span><br><span class="line">nr_requests 256</span><br><span class="line">nr_zones 0</span><br><span class="line">optimal_io_size 1048576</span><br><span class="line">physical_block_size 4096</span><br><span class="line">read_ahead_kb 2048</span><br><span class="line">rotational 1</span><br><span class="line">rq_affinity 1</span><br><span class="line">scheduler [mq-deadline] kyber bfq none</span><br><span class="line">stable_writes 1</span><br><span class="line">unpriv_sgio 0</span><br><span class="line">virt_boundary_mask 0</span><br><span class="line">wbt_lat_usec 75000</span><br><span class="line">write_cache write back</span><br><span class="line">write_same_max_bytes 33554432</span><br><span class="line">write_zeroes_max_bytes 33554432</span><br><span class="line">zone_append_max_bytes 0</span><br><span class="line">zoned none</span><br></pre></td></tr></table></figure>

  </div>
</article>


    <div class="blog-post-comments">
        <div id="utterances_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hardware"><span class="toc-number">1.</span> <span class="toc-text">Hardware</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Firmware"><span class="toc-number">1.1.</span> <span class="toc-text">Firmware</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#SSD"><span class="toc-number">1.1.1.</span> <span class="toc-text">SSD</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linux"><span class="toc-number">2.</span> <span class="toc-text">Linux</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#memory"><span class="toc-number">2.1.</span> <span class="toc-text">memory</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#CentOS-default-memory-setting-cause-issue"><span class="toc-number">2.1.1.</span> <span class="toc-text">CentOS default memory setting cause issue</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NIC-page-allocation-failure"><span class="toc-number">3.</span> <span class="toc-text">NIC page allocation failure</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#AMD-PCIE-4-issues"><span class="toc-number">3.1.</span> <span class="toc-text">AMD PCIE 4 issues</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Too-many-futex-overhead"><span class="toc-number">3.2.</span> <span class="toc-text">Too many futex overhead</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CentOS-7-7-sg3-utils-1-37-19-bug"><span class="toc-number">3.3.</span> <span class="toc-text">CentOS 7.7 sg3_utils-1.37-19 bug</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#report-qemu-img-convert-to-LVM-vol-and-show-this-error"><span class="toc-number">3.4.</span> <span class="toc-text">report qemu-img convert to LVM vol and show this error</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kernel-do-IRQ-X-Y-No-irq-handler-for-vector-irq-1"><span class="toc-number">3.5.</span> <span class="toc-text">kernel: do_IRQ: X.Y No irq handler for vector (irq -1)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#multipath-issue"><span class="toc-number">3.6.</span> <span class="toc-text">multipath issue</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PAM-err"><span class="toc-number">3.7.</span> <span class="toc-text">PAM err</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#troubleshooting-1"><span class="toc-number">3.8.</span> <span class="toc-text">troubleshooting-1</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#block-issue"><span class="toc-number">4.</span> <span class="toc-text">block issue</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2022/11/14/issues/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2022/11/14/issues/&text=issues"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2022/11/14/issues/&is_video=false&description=issues"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=issues&body=Check out this article: http://example.com/2022/11/14/issues/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2022/11/14/issues/&title=issues"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2022/11/14/issues/&name=issues&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2022/11/14/issues/&t=issues"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2023
    John Doe
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

    <script type="text/javascript">
      var utterances_repo = '67e8c052/67e8c052.github.io';
      var utterances_issue_term = 'pathname';
      var utterances_label = 'blog-comments';
      var utterances_theme = 'github-dark';

      (function(){
          var script = document.createElement('script');

          script.src = 'https://utteranc.es/client.js';
          script.setAttribute('repo', utterances_repo);
          script.setAttribute('issue-term', 'pathname');
          script.setAttribute('label', utterances_label);
          script.setAttribute('theme', utterances_theme);
          script.setAttribute('crossorigin', 'anonymous');
          script.async = true;
          (document.getElementById('utterances_thread')).appendChild(script);
      }());
  </script>

</body>
</html>
